# CompCars - AnÃ¡lisis de VehÃ­culos con Deep Learning

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2+-red.svg)](https://pytorch.org/)
[![uv](https://img.shields.io/badge/uv-package_manager-green.svg)](https://github.com/astral-sh/uv)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## DescripciÃ³n

Proyecto de investigaciÃ³n para anÃ¡lisis y clasificaciÃ³n de vehÃ­culos utilizando el dataset **CompCars**. Basado en **PyTorch**, **scikit-learn** y **pytorch-metric-learning**, implementa modelos de deep learning (ResNet50, ViT, CLIP), anÃ¡lisis de embeddings, clustering avanzado y visualizaciones comparativas para estudios de fine-tuning multi-vista.

### Objetivos Principales

- **Fine-tuning** de modelos pre-entrenados (ResNet50, ViT-B/32, CLIP)
- **AnÃ¡lisis comparativo** de arquitecturas y funciones de pÃ©rdida
- **Estudio CLIP layers** (progresiÃ³n 1-12 capas, vision/text components)
- **Clustering avanzado** con DBSCAN, HDBSCAN, Agglomerative
- **AnÃ¡lisis de embeddings** baseline vs fine-tuned
- **Soporte multi-vista** (front/rear) de vehÃ­culos
- **Visualizaciones** estadÃ­sticas y plots de entrenamiento

## ğŸ“‚ Arquitectura del Proyecto

```
Memoria/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ config/                   # Configuraciones
â”‚   â”‚   â””â”€â”€ TransformConfig.py   # Transformaciones de imÃ¡genes
â”‚   â”œâ”€â”€ data/                     # Procesamiento de datos      
â”‚   â”‚   â”œâ”€â”€ DataFrameMaker.py    # GeneraciÃ³n de dataset CSV
â”‚   â”‚   â””â”€â”€ MyDataset.py         # Dataset PyTorch personalizado
â”‚   â”œâ”€â”€ models/                   # Arquitecturas de modelos
â”‚   â”‚   â”œâ”€â”€ Criterions.py        # Funciones de pÃ©rdida (metric learning)
â”‚   â”‚   â”œâ”€â”€ MyVisionModel.py     # ResNet50, ViT-B/32 multi-vista
â”‚   â”‚   â””â”€â”€ MyCLIPModel.py       # CLIP (vision + text components)
â”‚   â”œâ”€â”€ pipeline/                 # Pipelines de ML
â”‚   â”‚   â”œâ”€â”€ FineTuningPipeline.py   # Pipeline de fine-tuning
â”‚   â”‚   â””â”€â”€ EmbeddingsPipeline.py   # Pipeline de anÃ¡lisis
â”‚   â””â”€â”€ utils/                    # Utilidades
â”‚       â”œâ”€â”€ ClusteringAnalyzer.py  # DBSCAN, HDBSCAN, etc.
â”‚       â”œâ”€â”€ DimensionalityReducer.py  # PCA, t-SNE, UMAP
â”‚       â””â”€â”€ ClusterVisualizer.py   # Visualizaciones
â”‚
â”œâ”€â”€ scripts/                      # Scripts de anÃ¡lisis
â”‚   â”œâ”€â”€ extraction/               # ExtracciÃ³n de resultados JSON â†’ CSV
â”‚   â”‚   â”œâ”€â”€ extract_vision_results.py
â”‚   â”‚   â””â”€â”€ extract_clip_layers_results.py
â”‚   â”œâ”€â”€ analysis/                 # AnÃ¡lisis estadÃ­stico
â”‚   â”‚   â”œâ”€â”€ analyze_vision_models.py
â”‚   â”‚   â””â”€â”€ analyze_clip_layers.py
â”‚   â”œâ”€â”€ visualization/            # GeneraciÃ³n de grÃ¡ficos
â”‚   â”‚   â”œâ”€â”€ visualize_training_history.py
â”‚   â”‚   â”œâ”€â”€ visualize_training_history_clip.py
â”‚   â”‚   â”œâ”€â”€ visualize_vision_models.py
â”‚   â”‚   â””â”€â”€ visualize_clip_layers.py
â”‚   â”œâ”€â”€ pipeline/                 # Scripts de entrenamiento
â”‚   â”‚   â”œâ”€â”€ Finetuning.py
â”‚   â”‚   â””â”€â”€ Embeddings.py
â”‚   â””â”€â”€ README.md                 # DocumentaciÃ³n de scripts
â”‚
â”œâ”€â”€ configs/                      # Configuraciones YAML
â”‚   â”œâ”€â”€ resnet50_*.yaml          # Configs ResNet50
â”‚   â”œâ”€â”€ vitb32_*.yaml            # Configs ViT-B/32
â”‚   â”œâ”€â”€ CLIP.yaml                # Config CLIP layers
â”‚   â””â”€â”€ embeddings.yaml          # Config anÃ¡lisis embeddings
â”‚
â”œâ”€â”€ dataset.csv                   # Dataset generado (163 modelos)
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ requirements-dev.txt          # Dependencias desarrollo
â”œâ”€â”€ pyproject.toml                # ConfiguraciÃ³n uv + proyecto
â””â”€â”€ README.md                    # Este archivo

# Carpetas ignoradas (no en git):
# results/                        â†’ Modelos, embeddings, anÃ¡lisis
# dataset/image/                  â†’ ImÃ¡genes CompCars (~214k)
# dataset/label/                  â†’ Metadatos y anotaciones
# .venv/                          â†’ Entorno virtual
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Prerrequisitos

- **Python 3.10+** (proyecto usa Python 3.10.19)
- **uv** - Gestor de paquetes rÃ¡pido ([InstalaciÃ³n](https://github.com/astral-sh/uv))
- **CUDA GPU** (opcional, recomendado para entrenamiento)
- **Git** para clonar el repositorio

### 2. Instalar uv (si no lo tienes)

```bash
# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Verificar instalaciÃ³n
uv --version
```

### 3. Clonar el repositorio

```bash
git clone https://github.com/diegovega2001/Memoria.git
cd Memoria
```

### 4. Configurar entorno con uv

```bash
# uv crearÃ¡ automÃ¡ticamente el entorno virtual y sincronizarÃ¡ dependencias
uv sync

# Verificar instalaciÃ³n
uv run python --version  # Debe mostrar Python 3.10.19
```

### 5. Verificar instalaciÃ³n

```bash
# Verificar PyTorch
uv run python -c "import torch; print(f'PyTorch: {torch.__version__}')"

# Verificar scikit-learn
uv run python -c "import sklearn; print(f'scikit-learn: {sklearn.__version__}')"

# Verificar CUDA (si disponible)
uv run python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

**Nota:** `uv` gestiona automÃ¡ticamente el entorno virtual, no es necesario activarlo manualmente.

## ğŸ’¡ Uso del Proyecto

### Flujo Completo de AnÃ¡lisis

Este proyecto estÃ¡ organizado en **4 fases** secuenciales:

#### **Fase 1: Fine-tuning de modelos**
Entrenar modelos con diferentes configuraciones.

```bash
# Ejemplo: Fine-tuning ResNet50 con metric learning
uv run scripts/pipeline/Finetuning.py --config configs/resnet50_metric_learning.yaml
```

#### **Fase 2: GeneraciÃ³n de embeddings y clustering**
Extraer embeddings y aplicar clustering.

```bash
# Generar embeddings y anÃ¡lisis de clustering
uv run scripts/pipeline/Embeddings.py --config configs/embeddings.yaml
```

#### **Fase 3: ExtracciÃ³n de resultados a CSV**
Consolidar resultados JSON en CSVs estructurados.

```bash
# Extraer resultados de vision models (ResNet50/ViT-B/32)
uv run scripts/extraction/extract_vision_results.py

# Extraer resultados de CLIP layers study
uv run scripts/extraction/extract_clip_layers_results.py
```

#### **Fase 4: AnÃ¡lisis estadÃ­stico y visualizaciones**
Generar anÃ¡lisis comparativos y grÃ¡ficos.

```bash
# AnÃ¡lisis estadÃ­stico
$env:PYTHONIOENCODING='utf-8'  # Windows PowerShell
uv run scripts/analysis/analyze_vision_models.py
uv run scripts/analysis/analyze_clip_layers.py

# Visualizaciones
uv run scripts/visualization/visualize_training_history.py
uv run scripts/visualization/visualize_vision_models.py
uv run scripts/visualization/visualize_clip_layers.py
```

### Configuraciones Disponibles

El proyecto incluye mÃºltiples configuraciones experimentales en `configs/`:

**Vision Models:**
- `resnet50_classification.yaml` - ResNet50 con CrossEntropy
- `resnet50_metric_learning.yaml` - ResNet50 con arcface/contrastive/ntxent/triplet/multisimilarity
- `vitb32_classification.yaml` - ViT-B/32 con CrossEntropy
- `vitb32_metric_learning.yaml` - ViT-B/32 con metric learning

**CLIP:**
- `CLIP.yaml` - Estudio de capas CLIP (1-12 layers, vision/text components)

**Embeddings:**
- `embeddings.yaml` - ConfiguraciÃ³n de anÃ¡lisis y clustering

## ğŸ“Š Resultados del Proyecto

El anÃ¡lisis completo generÃ³ **85 archivos** de resultados:

### Vision Models (ResNet50/ViT-B/32)
- **24 configuraciones** analizadas
- **6 CSVs** de datos extraÃ­dos
- **24 grÃ¡ficos** de curvas de entrenamiento
- **12 visualizaciones** comparativas
- **6 CSVs** de anÃ¡lisis estadÃ­stico

**Hallazgos principales:**
- âœ… ResNet50: **0.2665 ARI** (128% mejor que ViT-B/32)
- âœ… Metric Learning: **0.2058 ARI** (71% mejor que Classification)
- âœ… Front+Rear: **0.3254 ARI** (510% mejor que Front solo)
- âœ… Mejor config: **resnet50 + ntxent + front+rear** â†’ 0.8806 ARI, 82% clusters puros
- âœ… 22/24 configuraciones mejoraron con finetuning (+53% ARI promedio)

### CLIP Layers Study
- **24 configuraciones** (12 vision + 12 text, 1-12 layers)
- **3 CSVs** de datos extraÃ­dos
- **24 grÃ¡ficos** de curvas de entrenamiento
- **10 visualizaciones** de progresiÃ³n
- **3 CSVs** de anÃ¡lisis estadÃ­stico

**Hallazgos principales:**
- âœ… Vision component: **0.4439 ARI** (76% mejor que Text: 0.2526)
- âœ… Optimal layers: **11 layers** (vision), **9 layers** (text)
- âœ… CorrelaciÃ³n vision capasâ†’recall: **0.92** (muy fuerte)
- âœ… CorrelaciÃ³n text capasâ†’recall: **0.59** (moderada)
- âœ… Mejor config: **vision 11 layers** â†’ 0.4740 ARI, 56% clusters puros

### Estructura de Resultados

```
results/
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”œâ”€â”€ vision_models/          # 12 grÃ¡ficos comparativos
â”‚   â”‚   â””â”€â”€ clip_layers/            # 10 grÃ¡ficos de progresiÃ³n
â”‚   â”œâ”€â”€ statistics/                 # 9 CSVs de anÃ¡lisis estadÃ­stico
â”‚   â”œâ”€â”€ vision_models_results.csv   # 24 configs vision
â”‚   â””â”€â”€ clip_layers_results.csv     # 24 configs CLIP
â””â”€â”€ visualizations/
    â””â”€â”€ training_history_plots/     # 48 grÃ¡ficos de entrenamiento
```

Ver `scripts/README.md` para documentaciÃ³n detallada de cada fase.

## ğŸ”¬ CaracterÃ­sticas TÃ©cnicas

### **Modelos Soportados**
- **ResNet50** - Arquitectura CNN clÃ¡sica (2048-dim embeddings)
- **ViT-B/32** - Vision Transformer (768-dim embeddings)
- **CLIP** - Modelo multimodal vision + text (512-dim embeddings)

### **Objetivos de Entrenamiento**
- **Classification** - CrossEntropy loss para clasificaciÃ³n directa
- **Metric Learning** - Aprendizaje de espacio mÃ©trico con **pytorch-metric-learning**:
  - ArcFace Loss
  - Contrastive Loss
  - MultiSimilarity Loss
  - NTXent Loss (NT-Xent)
  - Triplet Loss

### **Clustering & AnÃ¡lisis**
- **Algoritmos (scikit-learn):** DBSCAN, HDBSCAN, Agglomerative, OPTICS
- **ReducciÃ³n dimensional:** PCA, t-SNE, UMAP
- **MÃ©tricas (scikit-learn):** ARI, NMI, Purity, Silhouette, % clusters puros
- **Visualizaciones:** t-SNE plots, heatmaps, rankings, confusion matrices

### **Multi-Vista**
- Soporte front/rear simultÃ¡neo
- FusiÃ³n de caracterÃ­sticas por concatenaciÃ³n
- AnÃ¡lisis comparativo front vs front+rear

### **Reproducibilidad**
- Seeds fijadas (Python, NumPy, PyTorch, CUDA)
- Configuraciones YAML versionadas
- Resultados JSON con timestamp
- Logging detallado de experimentos

## Dataset CompCars

El proyecto utiliza el dataset **CompCars** que contiene:

- **163 marcas de vehÃ­culos**
- **1,716 modelos diferentes**
- **~214,000 imÃ¡genes**
- **MÃºltiples viewpoints** (front, rear, side)
- **Bounding boxes** para cada vehÃ­culo
- **Metadatos** (aÃ±o, tipo, modelo)

### Estructura del CSV generado:

```csv
image_name,image_path,released_year,viewpoint,bbox,make,model,type
826a5fd082682c,dataset/image/135/947/unknown/826a5fd082682c.jpg,unknown,rear,"[96.0, 53.0, 817.0, 596.0]",Saab,SAAB 9X,Unknown
```

## ğŸ› ï¸ Dependencias Principales

El proyecto utiliza `uv` para gestiÃ³n rÃ¡pida de dependencias:

**Core ML:**
- `torch` >= 2.2.0 - Deep learning framework
- `torchvision` >= 0.17.0 - Modelos pre-entrenados y transformaciones
- `pytorch-metric-learning` >= 2.5.0 - Funciones de pÃ©rdida y minerÃ­a (ArcFace, NTXent, Triplet, etc.)
- `transformers` >= 4.38.0 - CLIP y otros modelos
- `scikit-learn` >= 1.4.0 - Clustering (DBSCAN, HDBSCAN) y mÃ©tricas (ARI, NMI)

**AnÃ¡lisis & VisualizaciÃ³n:**
- `pandas` >= 2.2.0 - ManipulaciÃ³n de datos
- `numpy` >= 1.26.0 - Operaciones numÃ©ricas
- `matplotlib` >= 3.8.0 - GrÃ¡ficos
- `seaborn` >= 0.13.0 - Visualizaciones estadÃ­sticas

**Utilidades:**
- `pyyaml` - Configuraciones YAML
- `tqdm` - Progress bars
- `pillow` - Procesamiento de imÃ¡genes

Ver `requirements.txt` para lista completa.

## ğŸ§ª Testing

```bash
# Ejecutar tests
uv run pytest tests/

# Tests con coverage
uv run pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ Scripts Ãštiles

```bash
# Ver versiones de dependencias
uv pip list

# Actualizar dependencias
uv sync --upgrade

# Ejecutar script especÃ­fico
uv run scripts/analysis/analyze_vision_models.py

# Verificar instalaciÃ³n de PyTorch
uv run python -c "import torch; print(torch.__version__)"
```

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## Autor

**Diego Vega** - [diegovega2001](https://github.com/diegovega2001)